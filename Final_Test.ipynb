{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00a334d1-edfb-4de4-94ee-6f0f00be35b9",
      "metadata": {
        "id": "00a334d1-edfb-4de4-94ee-6f0f00be35b9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.autograd\n",
        "import torch.utils.data\n",
        "import torchvision\n",
        "import torchvision.datasets as dataset\n",
        "import torchvision.transforms as T\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import warnings\n",
        "import os\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e491994f-c659-4243-b29d-6782809b411c",
      "metadata": {
        "id": "e491994f-c659-4243-b29d-6782809b411c"
      },
      "outputs": [],
      "source": [
        "RANDOM_SEED = 42\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "torch.cuda.manual_seed(RANDOM_SEED)\n",
        "torch.cuda.manual_seed_all(RANDOM_SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b60b4c13-54e8-42b5-bb57-bf47e1bf21c3",
      "metadata": {
        "id": "b60b4c13-54e8-42b5-bb57-bf47e1bf21c3",
        "outputId": "e4f8408d-de98-48a1-97ba-003e9a76a397"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class to Index Mapping: {'CT': 0, 'PN': 1, 'MP': 2, 'NC': 3, 'IC': 4, 'WM': 5}\n",
            "Index to Class Mapping: {0: 'CT', 1: 'PN', 2: 'MP', 3: 'NC', 4: 'IC', 5: 'WM'}\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import transforms\n",
        "import torchvision\n",
        "\n",
        "custom_class_mapping = {\n",
        "    'CT': 0,\n",
        "    'PN': 1,\n",
        "    'MP': 2,\n",
        "    'NC': 3,\n",
        "    'IC': 4,\n",
        "    'WM': 5,\n",
        "}\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((512,512)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "test_dataset = torchvision.datasets.ImageFolder(root='test_data', transform=transform)\n",
        "test_dataset.class_to_idx = custom_class_mapping\n",
        "print(\"Class to Index Mapping:\", test_dataset.class_to_idx)\n",
        "test_dataset.idx_to_class = {v: k for k, v in test_dataset.class_to_idx.items()}\n",
        "print(\"Index to Class Mapping:\", test_dataset.idx_to_class)\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3ab6301-51a2-42f9-93ce-6ea1244a3d97",
      "metadata": {
        "id": "e3ab6301-51a2-42f9-93ce-6ea1244a3d97"
      },
      "outputs": [],
      "source": [
        "class SAM(nn.Module):\n",
        "    def __init__(self, bias=False):\n",
        "        super(SAM, self).__init__()\n",
        "        self.bias = bias\n",
        "        self.conv = nn.Conv2d(in_channels=2, out_channels=1, kernel_size=7, stride=1, padding=3, dilation=1, bias=self.bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        max = torch.max(x, 1)[0].unsqueeze(1)\n",
        "        avg = torch.mean(x, 1).unsqueeze(1)\n",
        "        concat = torch.cat((max, avg), dim=1)\n",
        "        output = self.conv(concat)\n",
        "        output = output * x\n",
        "        return output\n",
        "\n",
        "class CAM(nn.Module):\n",
        "    def __init__(self, channels, r):\n",
        "        super(CAM, self).__init__()\n",
        "        self.channels = channels\n",
        "        self.r = r\n",
        "        self.linear = nn.Sequential(\n",
        "            nn.Linear(in_features=self.channels, out_features=self.channels // self.r, bias=True),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(in_features=self.channels // self.r, out_features=self.channels, bias=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        max = F.adaptive_max_pool2d(x, output_size=1)\n",
        "        avg = F.adaptive_avg_pool2d(x, output_size=1)\n",
        "        b, c, _, _ = x.size()\n",
        "        linear_max = self.linear(max.view(b, c)).view(b, c, 1, 1)\n",
        "        linear_avg = self.linear(avg.view(b, c)).view(b, c, 1, 1)\n",
        "        output = linear_max + linear_avg\n",
        "        output = torch.sigmoid(output) * x\n",
        "        return output\n",
        "\n",
        "class CBAM(nn.Module):\n",
        "    def __init__(self, channels, r):\n",
        "        super(CBAM, self).__init__()\n",
        "        self.channels = channels\n",
        "        self.r = r\n",
        "        self.sam = SAM(bias=False)\n",
        "        self.cam = CAM(channels=self.channels, r=self.r)\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.cam(x)\n",
        "        output = self.sam(output)\n",
        "        return output + x\n",
        "\n",
        "def conv_block(in_channels, out_channels):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, stride=1, padding=1),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.encoder(x)\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.decoder(x)\n",
        "\n",
        "\n",
        "class VGG19_CBAM(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(VGG19_CBAM, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "\n",
        "        self.encoder = Encoder(in_channels=self.in_channels, out_channels=64)\n",
        "\n",
        "        self.conv_block1 = nn.Sequential(\n",
        "            conv_block(64, 64),\n",
        "            CBAM(64, r=4),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "\n",
        "        self.conv_block2 = nn.Sequential(\n",
        "            conv_block(64, 128),\n",
        "            CBAM(128, r=4),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "\n",
        "        self.conv_block3 = nn.Sequential(\n",
        "            conv_block(128, 256),\n",
        "            *[conv_block(256, 256) for _ in range(2)],\n",
        "            CBAM(256, r=4),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "\n",
        "        self.conv_block4 = nn.Sequential(\n",
        "            conv_block(256, 512),\n",
        "            *[conv_block(512, 512) for _ in range(2)],\n",
        "            CBAM(512, r=4),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "\n",
        "        self.conv_block5 = nn.Sequential(\n",
        "            *[conv_block(512, 512) for _ in range(3)],\n",
        "            CBAM(512, r=4),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "\n",
        "        self.decoder1 = Decoder(in_channels=512, out_channels=256)\n",
        "        self.decoder2 = Decoder(in_channels=256, out_channels=128)\n",
        "        self.decoder3 = Decoder(in_channels=128, out_channels=64)\n",
        "        self.decoder4 = Decoder(in_channels=64, out_channels=in_channels)\n",
        "\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(output_size=(7, 7))\n",
        "\n",
        "        self.linear1 = nn.Sequential(\n",
        "            nn.Linear(in_features=3 * 7 * 7, out_features=4096, bias=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.linear2 = nn.Sequential(\n",
        "            nn.Linear(in_features=4096, out_features=4096, bias=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.linear3 = nn.Linear(in_features=4096, out_features=self.out_channels, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.conv_block1(x)\n",
        "        x = self.conv_block2(x)\n",
        "        x = self.conv_block3(x)\n",
        "        x = self.conv_block4(x)\n",
        "        x = self.conv_block5(x)\n",
        "\n",
        "        x = self.decoder1(x)\n",
        "        x = self.decoder2(x)\n",
        "        x = self.decoder3(x)\n",
        "        x = self.decoder4(x)\n",
        "\n",
        "        x = self.avg_pool(x)\n",
        "\n",
        "        x = x.view(x.shape[0], -1)\n",
        "\n",
        "        x = self.linear1(x)\n",
        "        x = self.linear2(x)\n",
        "        x = self.linear3(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16dbc444-8a6d-408e-8e38-2cc1cd8e5a44",
      "metadata": {
        "id": "16dbc444-8a6d-408e-8e38-2cc1cd8e5a44"
      },
      "outputs": [],
      "source": [
        "class CustomLoss(nn.Module):\n",
        "    def __init__(self, alpha=None, gamma=2.0, ce_weight=0.5, focal_weight=0.3, mcc_weight=0.1, f1_weight=0.1, epsilon=1e-7, label_smoothing=0.1):\n",
        "        super(CustomLoss, self).__init__()\n",
        "        self.gamma = gamma\n",
        "        self.ce_weight = ce_weight\n",
        "        self.focal_weight = focal_weight\n",
        "        self.mcc_weight = mcc_weight\n",
        "        self.f1_weight = f1_weight\n",
        "        self.epsilon = epsilon\n",
        "        self.label_smoothing = label_smoothing\n",
        "\n",
        "        if alpha is None:\n",
        "            self.alpha = torch.ones(6)\n",
        "        else:\n",
        "            self.alpha = torch.tensor(alpha, dtype=torch.float32)\n",
        "\n",
        "    def forward(self, y_pred, labels, weights=None):\n",
        "        y_true = F.one_hot(labels, num_classes=y_pred.size(1)).float()\n",
        "        y_true = y_true * (1 - self.label_smoothing) + self.label_smoothing / y_pred.size(1)\n",
        "\n",
        "        if self.alpha is not None:\n",
        "            self.alpha = self.alpha.to(y_pred.device)\n",
        "\n",
        "        y_pred = torch.clamp(F.softmax(y_pred, dim=1), self.epsilon, 1.0 - self.epsilon)\n",
        "\n",
        "        ce_loss = -torch.sum(y_true * torch.log(y_pred), dim=1)\n",
        "\n",
        "        focal_loss = -torch.sum(self.alpha * (1 - y_pred) ** self.gamma * y_true * torch.log(y_pred), dim=1)\n",
        "\n",
        "        if weights is None:\n",
        "            weights = torch.ones(y_true.shape[0], dtype=torch.float32).to(y_pred.device)\n",
        "        else:\n",
        "            weights = weights.to(y_pred.device)\n",
        "\n",
        "        tp = torch.sum(weights[:, None] * y_true * y_pred, dim=0)\n",
        "        tn = torch.sum(weights[:, None] * (1 - y_true) * (1 - y_pred), dim=0)\n",
        "        fp = torch.sum(weights[:, None] * (1 - y_true) * y_pred, dim=0)\n",
        "        fn = torch.sum(weights[:, None] * y_true * (1 - y_pred), dim=0)\n",
        "\n",
        "        denominator = torch.sqrt((tp + fp + self.epsilon) * (tp + fn + self.epsilon) * (tn + fp + self.epsilon) * (tn + fn + self.epsilon))\n",
        "\n",
        "        numerator = tp * tn - fp * fn\n",
        "        mcc_loss = 1.0 - torch.sum(numerator / (denominator + self.epsilon))\n",
        "\n",
        "        precision = tp / (tp + fp + self.epsilon)\n",
        "        recall = tp / (tp + fn + self.epsilon)\n",
        "        f1_score = 2 * (precision * recall) / (precision + recall + self.epsilon)\n",
        "\n",
        "        f1_loss = 1.0 - f1_score.mean()\n",
        "\n",
        "        total_loss = (self.ce_weight * ce_loss.mean() +\n",
        "                      self.focal_weight * focal_loss.mean() +\n",
        "                      self.mcc_weight * mcc_loss +\n",
        "                      self.f1_weight * f1_loss)\n",
        "\n",
        "        return total_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b26e7b80-840d-4b60-8b2c-19487ae2a657",
      "metadata": {
        "id": "b26e7b80-840d-4b60-8b2c-19487ae2a657"
      },
      "outputs": [],
      "source": [
        "class SAM(nn.Module):\n",
        "    def __init__(self, bias=False):\n",
        "        super(SAM, self).__init__()\n",
        "        self.bias = bias\n",
        "        self.conv = nn.Conv2d(in_channels=2, out_channels=1, kernel_size=7, stride=1, padding=3, dilation=1, bias=self.bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        max_pool = torch.max(x, 1)[0].unsqueeze(1)\n",
        "        avg_pool = torch.mean(x, 1).unsqueeze(1)\n",
        "        concat = torch.cat((max_pool, avg_pool), dim=1)\n",
        "        output = self.conv(concat)\n",
        "        output = torch.sigmoid(output)  # Apply sigmoid to get attention map\n",
        "        return output * x\n",
        "\n",
        "class CAM(nn.Module):\n",
        "    def __init__(self, channels, r=16):\n",
        "        super(CAM, self).__init__()\n",
        "        self.channels = channels\n",
        "        self.r = r\n",
        "        self.linear = nn.Sequential(\n",
        "            nn.Linear(in_features=channels, out_features=channels // r, bias=True),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(in_features=channels // r, out_features=channels, bias=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        max_pool = F.adaptive_max_pool2d(x, output_size=1)\n",
        "        avg_pool = F.adaptive_avg_pool2d(x, output_size=1)\n",
        "        max_pool = max_pool.view(max_pool.size(0), -1)\n",
        "        avg_pool = avg_pool.view(avg_pool.size(0), -1)\n",
        "        max_out = self.linear(max_pool)\n",
        "        avg_out = self.linear(avg_pool)\n",
        "        out = torch.sigmoid(max_out + avg_out).view(x.size(0), x.size(1), 1, 1)\n",
        "        return out * x\n",
        "\n",
        "class CBAM(nn.Module):\n",
        "    def __init__(self, channels, r=16):\n",
        "        super(CBAM, self).__init__()\n",
        "        self.cam = CAM(channels, r)\n",
        "        self.sam = SAM()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.cam(x)\n",
        "        out = self.sam(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8aa6b32b-97eb-4786-8e45-563e276d4b87",
      "metadata": {
        "id": "8aa6b32b-97eb-4786-8e45-563e276d4b87"
      },
      "outputs": [],
      "source": [
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv2 = nn.Conv2d(\n",
        "            out_channels,\n",
        "            out_channels,\n",
        "            kernel_size=3,\n",
        "            stride=stride,\n",
        "            padding=1,\n",
        "            bias=False,\n",
        "        )\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv3 = nn.Conv2d(\n",
        "            out_channels, out_channels * self.expansion, kernel_size=1, bias=False\n",
        "        )\n",
        "        self.bn3 = nn.BatchNorm2d(out_channels * self.expansion)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.cbam = CBAM(out_channels * self.expansion)\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "        out = self.cbam(out)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cb5e3fb-793f-40c1-9446-be388f180ecc",
      "metadata": {
        "id": "5cb5e3fb-793f-40c1-9446-be388f180ecc"
      },
      "outputs": [],
      "source": [
        "class GAFNET_CBAM(nn.Module):\n",
        "    def __init__(self, in_channels, num_classes):\n",
        "        super(GAFNET_CBAM, self).__init__()\n",
        "        self.in_channels = 64\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_channels, 64, kernel_size=7, stride=2, padding=3, bias=False\n",
        "        )\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        self.layer1 = self._make_layer(Bottleneck, 64, 3)\n",
        "        self.layer2 = self._make_layer(Bottleneck, 128, 4, stride=2)\n",
        "        self.layer3 = self._make_layer(Bottleneck, 256, 6, stride=2)\n",
        "        self.layer4 = self._make_layer(Bottleneck, 512, 3, stride=2)\n",
        "        self.layer5 = self._make_layer(Bottleneck, 1024, 3, stride=2)\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(1024 * Bottleneck.expansion, num_classes)\n",
        "\n",
        "        self.skip_connection = nn.Conv2d(\n",
        "            in_channels,\n",
        "            1024 * Bottleneck.expansion,\n",
        "            kernel_size=1,\n",
        "            stride=32,\n",
        "            bias=False,\n",
        "        )\n",
        "        self.skip_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "\n",
        "    def _make_layer(self, block, out_channels, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.in_channels != out_channels * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(\n",
        "                    self.in_channels,\n",
        "                    out_channels * block.expansion,\n",
        "                    kernel_size=1,\n",
        "                    stride=stride,\n",
        "                    bias=False,\n",
        "                ),\n",
        "                nn.BatchNorm2d(out_channels * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
        "        self.in_channels = out_channels * block.expansion\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(block(self.in_channels, out_channels))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        skip = self.skip_connection(x)\n",
        "        skip = self.skip_pool(skip)  # Ensure the skip connection is resized properly\n",
        "        skip = torch.flatten(skip, 1)\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = self.layer5(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        # Ensure the dimensions match before adding\n",
        "        if x.shape[1] == skip.shape[1]:\n",
        "            x += skip\n",
        "\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e002041-6100-4580-8097-a6b1e43cdded",
      "metadata": {
        "id": "8e002041-6100-4580-8097-a6b1e43cdded"
      },
      "outputs": [],
      "source": [
        "class CustomLoss(nn.Module):\n",
        "    def __init__(self, alpha=None, gamma=2.0, ce_weight=0.5, focal_weight=0.3, mcc_weight=0.1, f1_weight=0.1, epsilon=1e-7, label_smoothing=0.1):\n",
        "        super(CustomLoss, self).__init__()\n",
        "        self.gamma = gamma\n",
        "        self.ce_weight = ce_weight\n",
        "        self.focal_weight = focal_weight\n",
        "        self.mcc_weight = mcc_weight\n",
        "        self.f1_weight = f1_weight\n",
        "        self.epsilon = epsilon\n",
        "        self.label_smoothing = label_smoothing\n",
        "\n",
        "        if alpha is None:\n",
        "            self.alpha = torch.ones(6)\n",
        "        else:\n",
        "            self.alpha = torch.tensor(alpha, dtype=torch.float32)\n",
        "\n",
        "    def forward(self, y_pred, labels, weights=None):\n",
        "        y_true = F.one_hot(labels, num_classes=y_pred.size(1)).float()\n",
        "\n",
        "        y_true = y_true * (1 - self.label_smoothing) + self.label_smoothing / y_pred.size(1)\n",
        "\n",
        "        if self.alpha is not None:\n",
        "            self.alpha = self.alpha.to(y_pred.device)\n",
        "\n",
        "        y_pred = torch.clamp(F.softmax(y_pred, dim=1), self.epsilon, 1.0 - self.epsilon)\n",
        "\n",
        "        ce_loss = -torch.sum(y_true * torch.log(y_pred), dim=1)\n",
        "\n",
        "        focal_loss = -torch.sum(self.alpha * (1 - y_pred) ** self.gamma * y_true * torch.log(y_pred), dim=1)\n",
        "\n",
        "        if weights is None:\n",
        "            weights = torch.ones(y_true.shape[0], dtype=torch.float32).to(y_pred.device)\n",
        "        else:\n",
        "            weights = weights.to(y_pred.device)\n",
        "\n",
        "        tp = torch.sum(weights[:, None] * y_true * y_pred, dim=0)\n",
        "        tn = torch.sum(weights[:, None] * (1 - y_true) * (1 - y_pred), dim=0)\n",
        "        fp = torch.sum(weights[:, None] * (1 - y_true) * y_pred, dim=0)\n",
        "        fn = torch.sum(weights[:, None] * y_true * (1 - y_pred), dim=0)\n",
        "\n",
        "        denominator = torch.sqrt((tp + fp + self.epsilon) * (tp + fn + self.epsilon) * (tn + fp + self.epsilon) * (tn + fn + self.epsilon))\n",
        "\n",
        "        numerator = tp * tn - fp * fn\n",
        "        mcc_loss = 1.0 - torch.sum(numerator / (denominator + self.epsilon))\n",
        "\n",
        "        precision = tp / (tp + fp + self.epsilon)\n",
        "        recall = tp / (tp + fn + self.epsilon)\n",
        "        f1_score = 2 * (precision * recall) / (precision + recall + self.epsilon)\n",
        "\n",
        "        f1_loss = 1.0 - f1_score.mean()\n",
        "\n",
        "        total_loss = (self.ce_weight * ce_loss.mean() +\n",
        "                      self.focal_weight * focal_loss.mean() +\n",
        "                      self.mcc_weight * mcc_loss +\n",
        "                      self.f1_weight * f1_loss)\n",
        "\n",
        "        return total_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30f055c0-cff1-4f35-bc0c-ddfd8ce4efe4",
      "metadata": {
        "id": "30f055c0-cff1-4f35-bc0c-ddfd8ce4efe4"
      },
      "outputs": [],
      "source": [
        "class SAM(nn.Module):\n",
        "    def __init__(self, bias=False):\n",
        "        super(SAM, self).__init__()\n",
        "        self.bias = bias\n",
        "        self.conv = nn.Conv2d(in_channels=2, out_channels=1, kernel_size=7, stride=1, padding=3, dilation=1, bias=self.bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        max = torch.max(x,1)[0].unsqueeze(1)\n",
        "        avg = torch.mean(x,1).unsqueeze(1)\n",
        "        concat = torch.cat((max,avg), dim=1)\n",
        "        output = self.conv(concat)\n",
        "        output = output * x\n",
        "        return output\n",
        "\n",
        "class CAM(nn.Module):\n",
        "    def __init__(self, channels, r):\n",
        "        super(CAM, self).__init__()\n",
        "        self.channels = channels\n",
        "        self.r = r\n",
        "        self.linear = nn.Sequential(\n",
        "            nn.Linear(in_features=self.channels, out_features=self.channels//self.r, bias=True),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(in_features=self.channels//self.r, out_features=self.channels, bias=True))\n",
        "\n",
        "    def forward(self, x):\n",
        "        max = F.adaptive_max_pool2d(x, output_size=1)\n",
        "        avg = F.adaptive_avg_pool2d(x, output_size=1)\n",
        "        b, c, _, _ = x.size()\n",
        "        linear_max = self.linear(max.view(b,c)).view(b, c, 1, 1)\n",
        "        linear_avg = self.linear(avg.view(b,c)).view(b, c, 1, 1)\n",
        "        output = linear_max + linear_avg\n",
        "        output = F.sigmoid(output) * x\n",
        "        return output\n",
        "\n",
        "class CBAM(nn.Module):\n",
        "    def __init__(self, channels, r=16):\n",
        "        super(CBAM, self).__init__()\n",
        "        self.channels = channels\n",
        "        self.r = r\n",
        "        self.sam = SAM(bias=False)\n",
        "        self.cam = CAM(channels=self.channels, r=self.r)\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.cam(x)\n",
        "        output = self.sam(output)\n",
        "        return output + x\n",
        "\n",
        "def conv_block(in_channels, out_channels):\n",
        "    return nn.Sequential(nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, stride=1, padding=1),\n",
        "                         nn.BatchNorm2d(out_channels),\n",
        "                         nn.ReLU())\n",
        "\n",
        "class VGG19_CBAM2(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "\n",
        "        self.conv_block1 = nn.Sequential(nn.Conv2d(in_channels=self.in_channels, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
        "                                         nn.BatchNorm2d(64),\n",
        "                                         nn.ReLU(),\n",
        "                                         conv_block(64, 64),\n",
        "                                         CBAM(64, r=4),\n",
        "                                         nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "        self.conv_block2 = nn.Sequential(nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
        "                                         nn.BatchNorm2d(128),\n",
        "                                         nn.ReLU(),\n",
        "                                         conv_block(128, 128),\n",
        "                                         CBAM(128, r=4),\n",
        "                                         nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "        self.conv_block3 = nn.Sequential(nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
        "                                         nn.BatchNorm2d(256),\n",
        "                                         nn.ReLU(),\n",
        "                                         *[conv_block(256, 256) for _ in range(3)],\n",
        "                                         CBAM(256, r=4),\n",
        "                                         nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "        self.conv_block4 = nn.Sequential(nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
        "                                         nn.BatchNorm2d(512),\n",
        "                                         nn.ReLU(),\n",
        "                                         *[conv_block(512, 512) for _ in range(3)],\n",
        "                                         CBAM(512, r=4),\n",
        "                                         nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "        self.conv_block5 = nn.Sequential(*[conv_block(512, 512) for _ in range(4)],\n",
        "                                         CBAM(512, r=4),\n",
        "                                         nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(output_size=(7,7))\n",
        "\n",
        "        self.linear1 = nn.Sequential(nn.Linear(in_features=7*7*512, out_features=4096, bias=True),\n",
        "                                     nn.Dropout(0.5),\n",
        "                                     nn.ReLU())\n",
        "        self.linear2 = nn.Sequential(nn.Linear(in_features=4096, out_features=4096, bias=True),\n",
        "                                     nn.Dropout(0.5),\n",
        "                                     nn.ReLU())\n",
        "        self.linear3 = nn.Linear(in_features=4096, out_features=self.out_channels, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_block1(x)\n",
        "        x = self.conv_block2(x)\n",
        "        x = self.conv_block3(x)\n",
        "        x = self.conv_block4(x)\n",
        "        x = self.conv_block5(x)\n",
        "        x = self.avg_pool(x)\n",
        "        x = self.linear1(x.view(x.shape[0], -1))\n",
        "        x = self.linear2(x)\n",
        "        x = self.linear3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64e340dc-b772-4a7e-aa3d-19104a8ef33f",
      "metadata": {
        "id": "64e340dc-b772-4a7e-aa3d-19104a8ef33f"
      },
      "outputs": [],
      "source": [
        "model3 = VGG19_CBAM2(in_channels=3, out_channels=6)\n",
        "state_dict = torch.load(\"saved_models/model3.pth\")\n",
        "model3.load_state_dict(state_dict)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=0.0001, weight_decay=0.005)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "total_epochs = 10\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model3 = model3.to(device)\n",
        "\n",
        "\n",
        "model2 = GAFNET_CBAM(in_channels=3,num_classes=6)\n",
        "state_dict = torch.load(\"saved_models/model2.pth\")\n",
        "model2.load_state_dict(state_dict)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "optimizer = optim.AdamW(model.parameters(), lr=0.0001, weight_decay=0.005)\n",
        "criterion = CustomLoss()\n",
        "total_epochs = 8\n",
        "model2 = model2.to(device)\n",
        "\n",
        "model = VGG19_CBAM(in_channels=3, out_channels=6)\n",
        "state_dict = torch.load(\"saved_models/model1.pth\")\n",
        "model.load_state_dict(state_dict)\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "optimizer = optim.AdamW(model.parameters(), lr=0.0001, weight_decay=0.005)\n",
        "criterion = CustomLoss()\n",
        "total_epochs = 10\n",
        "model = model.to(device)\n",
        "\n",
        "model.eval()\n",
        "model2.eval()\n",
        "model3.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f667c18c-22d4-4d90-86da-59e229d762aa",
      "metadata": {
        "id": "f667c18c-22d4-4d90-86da-59e229d762aa"
      },
      "outputs": [],
      "source": [
        "w1, w2, w3 = 0.546, 0.464, 0.527\n",
        "total_weight = w1 + w2 + w3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e887f01f-f0c8-4ac9-8544-a0ac6b004178",
      "metadata": {
        "id": "e887f01f-f0c8-4ac9-8544-a0ac6b004178",
        "outputId": "c59a7dbf-5e5c-4103-eb3c-1d1851186ec2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed 100/1125 batches.\n",
            "Processed 200/1125 batches.\n",
            "Processed 300/1125 batches.\n",
            "Processed 400/1125 batches.\n",
            "Processed 500/1125 batches.\n",
            "Processed 600/1125 batches.\n",
            "Processed 700/1125 batches.\n",
            "Processed 800/1125 batches.\n",
            "Processed 900/1125 batches.\n",
            "Processed 1000/1125 batches.\n",
            "Processed 1100/1125 batches.\n",
            "Processed 1125/1125 batches.\n",
            "Accuracy: 0.9673\n",
            "F1-Score: 0.9634\n",
            "Precision: 0.9670\n",
            "Sensitivity (Recall): 0.9600\n",
            "Specificity: 0.9860\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "predictions = []\n",
        "true_labels = []\n",
        "\n",
        "for batch_idx, (images, labels) in enumerate(test_loader):\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output1 = model(images)\n",
        "        output2 = model2(images)\n",
        "        output3 = model3(images)\n",
        "\n",
        "        weighted_avg_outputs = (w1 * output1 + w2 * output2 + w3 * output3) / total_weight\n",
        "        _, preds = torch.max(weighted_avg_outputs, 1)\n",
        "\n",
        "        predictions.extend(preds.cpu().numpy())\n",
        "        true_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    if (batch_idx + 1) % 100 == 0 or (batch_idx + 1) == len(test_loader):\n",
        "        print(f\"Processed {batch_idx + 1}/{len(test_loader)} batches.\")\n",
        "\n",
        "predictions = np.array(predictions)\n",
        "true_labels = np.array(true_labels)\n",
        "\n",
        "accuracy = accuracy_score(true_labels, predictions)\n",
        "\n",
        "f1 = f1_score(true_labels, predictions, average='macro')\n",
        "\n",
        "precision = precision_score(true_labels, predictions, average='macro')\n",
        "\n",
        "sensitivity = recall_score(true_labels, predictions, average='macro')\n",
        "\n",
        "conf_matrix = confusion_matrix(true_labels, predictions)\n",
        "specificity_per_class = []\n",
        "for i in range(len(custom_class_mapping)):\n",
        "    tn = conf_matrix.sum() - conf_matrix[i, :].sum() - conf_matrix[:, i].sum() + conf_matrix[i, i]\n",
        "    fp = conf_matrix[:, i].sum() - conf_matrix[i, i]\n",
        "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "    specificity_per_class.append(specificity)\n",
        "specificity = np.mean(specificity_per_class)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Sensitivity (Recall): {sensitivity:.4f}\")\n",
        "print(f\"Specificity: {specificity:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6399685b-34bc-4859-a303-6b79cf474eac",
      "metadata": {
        "id": "6399685b-34bc-4859-a303-6b79cf474eac"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}